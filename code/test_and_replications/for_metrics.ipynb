{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating metrics utility\n",
    "This is a utility tool created by willim to allow easy exploration of the work we have done and the metrics which correspond to the solutions we have found.\n",
    "\n",
    "Good science should be replicable. Running this file from a to z will create a dataset containing the raw images of each scenes, and do so for each cleaning method we found.  \n",
    "\n",
    "The structure of the the resulting pickle will be:\n",
    "level 1 : method or raw\n",
    "level 2: scene\n",
    "\n",
    "The resulting arrays are normalized to 1 and stored safely into the pickle, ready for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run all of this next section for the rest to go smoothly.**\n",
    "\n",
    "In next cell just enter the folder in which you have placed your dataset then run the entire notebook, and for data analysis open data_manipulation.ipynb or image_enhancement.ipynb for asthetics manipulation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = r\"C:\\Users\\WillQuantique\\OneDrive - univ-lyon2.fr\\Fac\\M1\\DataChallege\\git\\M1_S8_dataChallenge_24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df1 = pd.read_hdf(dataset_location + r'\\scene.hdf5')\n",
    "scene_df2 = pd.read_hdf(dataset_location + r'\\scene2.hdf5')\n",
    "scene_df3 = pd.read_hdf(dataset_location + r'\\scene3.hdf5')\n",
    "car_scene_df1 = pd.read_hdf(dataset_location + r'\\car_scene.hdf5')\n",
    "car_scene_df2 = pd.read_hdf(dataset_location + r'\\car_scene2.hdf5')\n",
    "car_scene_df3 = pd.read_hdf(dataset_location + r'\\car_scene3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_df1 = pd.read_hdf(dataset_location+r\"\\calibration_set_1.hdf5\")\n",
    "calibration_df2 = pd.read_hdf(dataset_location+r\"\\calibration_set_2.hdf5\")\n",
    "car_calibration_df1 = pd.read_hdf(dataset_location+r\"\\car_calibration_set_1.hdf5\")\n",
    "car_calibration_df2 = pd.read_hdf(dataset_location+r\"\\car_calibration_set_2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, min_val=0.0, max_val=1.0):\n",
    "    \"\"\"\n",
    "    Normalizes the values of a NumPy array to a specified range.\n",
    "\n",
    "    Args:\n",
    "        arr (numpy.ndarray): Input array to be normalized.\n",
    "        min_val (float): Minimum value of the normalized range (default: 0.0).\n",
    "        max_val (float): Maximum value of the normalized range (default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized array with values in the specified range.\n",
    "    \"\"\"\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    normalized_arr = (arr - arr_min) / (arr_max - arr_min)\n",
    "    normalized_arr = normalized_arr * (max_val - min_val) + min_val\n",
    "    return normalized_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calibration matching\n",
    "Here is the method for calibration matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the closest calibration image\n",
    "def find_closest_calibration_image(scene_temp, calibration_data):\n",
    "    calibration_temperatures = calibration_data['t_fpa'].values\n",
    "    closest_index = (np.abs(calibration_temperatures - scene_temp)).argmin()\n",
    "    return calibration_data.iloc[closest_index]['image']\n",
    "\n",
    "# Function to apply denoising using the closest calibration image\n",
    "def denoise_image(scene_image, calibration_image):\n",
    "    return scene_image - calibration_image\n",
    "\n",
    "def calibration_matching(scene_df, calibration_df):\n",
    "    corrected_scene_images = []\n",
    "    for i, row in scene_df.iterrows():\n",
    "        scene_temp = row['t_fpa']\n",
    "        scene_image = row['image']\n",
    "        closest_calibration_image = find_closest_calibration_image(scene_temp, calibration_df)\n",
    "        corrected_image = denoise_image(scene_image, closest_calibration_image)\n",
    "        corrected_scene_images.append(corrected_image)\n",
    "\n",
    "# Convert corrected_scene_images to numpy array\n",
    "    return np.array(corrected_scene_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear regression\n",
    "\n",
    "Here is the linear regression method (best results over all), created for challenge two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the device we have the parameter estimation function.\n",
    "\n",
    "Note that all calibration df returned the same parameters (to the best of my observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters(calibration_df):\n",
    "    calibration_images = calibration_df['image'].values\n",
    "    calibration_temperatures = np.vstack((calibration_df['t_fpa'].values, calibration_df['t_cn'].values)).T\n",
    "    \n",
    "    # Ensure calibration_images is a numeric array\n",
    "    calibration_images = np.array(calibration_images.tolist(), dtype=np.float32)\n",
    "    calibration_temperatures = np.array(calibration_temperatures, dtype=np.float32)\n",
    "\n",
    "    # Convert calibration images and temperatures to PyTorch tensors\n",
    "    calibration_images_tensor = torch.tensor(calibration_images, dtype=torch.float32).to(device)\n",
    "    calibration_temperatures_tensor = torch.tensor(calibration_temperatures, dtype=torch.float32).to(device)\n",
    "\n",
    "    height, width = calibration_images_tensor.shape[1:]\n",
    "    num_pixels = height * width\n",
    "\n",
    "    # Reshape images for linear regression\n",
    "    images_reshaped = calibration_images_tensor.view(calibration_images_tensor.shape[0], -1)\n",
    "    calibration_temperatures_tensor = calibration_temperatures_tensor.to(device)\n",
    "\n",
    "    # Add bias term for intercept in linear regression\n",
    "    X = torch.cat([calibration_temperatures_tensor, torch.ones(calibration_temperatures_tensor.size(0), 1).to(device)], dim=1)\n",
    "\n",
    "    # Perform linear regression using torch.linalg.lstsq\n",
    "    responsivities_and_offsets = torch.linalg.lstsq(X, images_reshaped).solution\n",
    "\n",
    "    # Separate responsivities and offsets\n",
    "    responsivities = responsivities_and_offsets[:-1, :].T\n",
    "    offsets = responsivities_and_offsets[-1, :]\n",
    "\n",
    "    # Reshape back to original image shape\n",
    "    offsets = offsets.view(height, width).cpu().numpy()\n",
    "    responsivities = responsivities.view(height, width, -1).cpu().numpy()\n",
    "\n",
    "    return offsets, responsivities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function applies the array of parameters to one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_correction(scene_image, offsets, responsivities, scene_temp, avg_black_body_temp):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    scene_image_tensor = torch.tensor(scene_image, dtype=torch.float32).to(device)\n",
    "    offsets_tensor = torch.tensor(offsets, dtype=torch.float32).to(device)\n",
    "    responsivities_tensor = torch.tensor(responsivities, dtype=torch.float32).to(device)\n",
    "    scene_temp_tensor = torch.tensor(scene_temp, dtype=torch.float32).to(device)\n",
    "    avg_black_body_temp_tensor = torch.tensor(avg_black_body_temp, dtype=torch.float32).to(device)\n",
    "\n",
    "    height, width = scene_image_tensor.shape\n",
    "    corrected_image_tensor = torch.zeros_like(scene_image_tensor)\n",
    "\n",
    "    # Calculate expected value\n",
    "    intercepts_tensor = offsets_tensor\n",
    "    coef_fpa_tensor = responsivities_tensor[:, :, 0]\n",
    "    coef_cn_tensor = responsivities_tensor[:, :, 1]\n",
    "    expected_value = intercepts_tensor + coef_fpa_tensor * scene_temp_tensor + coef_cn_tensor * avg_black_body_temp_tensor\n",
    "    \n",
    "    # Apply correction\n",
    "    corrected_image_tensor = scene_image_tensor - expected_value\n",
    "\n",
    "    # Convert the result back to a numpy array if needed\n",
    "    corrected_image = corrected_image_tensor.cpu().numpy()\n",
    "\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is all one need to run to estimate and apply parameters from a calibration df to a scene df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applier(calibration_df,scene_df):\n",
    "    offset, gain = estimate_parameters(calibration_df)\n",
    "    avg_black_body_temp = calibration_df['t_cn'].mean()\n",
    "    # Process each scene image\n",
    "    corrected_scene_images = []\n",
    "    \n",
    "    for index, row in scene_df.iterrows():\n",
    "        scene_image = row['image']\n",
    "        scene_temp = row['t_fpa']\n",
    "        corrected_image = apply_correction(scene_image, offset, gain, scene_temp, avg_black_body_temp)\n",
    "        corrected_scene_images.append(corrected_image)\n",
    "\n",
    "    # Convert corrected_scene_images to numpy array\n",
    "    return np.array(corrected_scene_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pseudo-calibration\n",
    "\n",
    "The method we found for challenge 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*slicing arrays into block of n pixels, using stride < block size to create overlap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_array(arr, num=10, stride=8):\n",
    "    t, x, y = arr.shape\n",
    "    \n",
    "    slices = []\n",
    "    \n",
    "    for i in range(0, x - x // num + 1, stride):\n",
    "        for j in range(0, y - y // num + 1, stride):\n",
    "            slice_x_start = i\n",
    "            slice_x_end = i + x // num\n",
    "            slice_y_start = j\n",
    "            slice_y_end = j + y // num\n",
    "            \n",
    "            slice_ij = arr[:, slice_x_start:slice_x_end, slice_y_start:slice_y_end]\n",
    "            slices.append((slice_ij, (slice_x_start, slice_x_end, slice_y_start, slice_y_end)))\n",
    "    \n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rebuilding the arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_array(slices, original_shape, num=10):\n",
    "    t, x, y = original_shape\n",
    "    \n",
    "    # Initialize an empty array with the original shape\n",
    "    rebuilt_array = np.zeros((x, y))\n",
    "    weight = np.zeros((x, y))\n",
    "    \n",
    "    for slice_ij, (slice_x_start, slice_x_end, slice_y_start, slice_y_end) in slices:\n",
    "        rebuilt_array[slice_x_start:slice_x_end, slice_y_start:slice_y_end] += slice_ij\n",
    "        weight[slice_x_start:slice_x_end, slice_y_start:slice_y_end] += 1\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    weight[weight == 0] = 1\n",
    "    return rebuilt_array / weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*sort images by order of growing variance, allows us to reorder blocks independant of time and give a better pick for the mean*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_uniform_pictures(arr):\n",
    "    \"\"\"\n",
    "    Sort (t, x, y) array's t slices from most uniform to least uniform.\n",
    "\n",
    "    Parameters:\n",
    "    arr (np.ndarray): Input 3D array of shape (t, x, y).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A 3D array where the t slices are sorted by uniformity.\n",
    "    \"\"\"\n",
    "    t, x, y = arr.shape\n",
    "    \n",
    "    # Compute the variance for each t slice\n",
    "    variances = np.var(arr, axis=(1, 2))\n",
    "    \n",
    "    # Get the sorted indices based on variances\n",
    "    sorted_indices = np.argsort(variances)\n",
    "    \n",
    "    # Extract and sort the t slices\n",
    "    sorted_slices = arr[sorted_indices]\n",
    "    \n",
    "    return sorted_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pick one out of n images in the given sequence and return the corresponding array*\n",
    "\n",
    "I advise to use `int(len(arr)/n)` for the sake of looping (see the end of the file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_regular_slices(arr, num):\n",
    "    \"\"\"\n",
    "    Pick a tenth of all t slices in a regular order from a (t, x, y) array.\n",
    "\n",
    "    Parameters:\n",
    "    arr (np.ndarray): Input 3D array of shape (t, x, y).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A 3D array with a tenth of the t slices picked in a regular order.\n",
    "    \"\"\"\n",
    "    t, x, y = arr.shape\n",
    "    \n",
    "    # Compute the indices to pick a tenth of the t slices at regular intervals\n",
    "    step = t // num\n",
    "    indices = np.arange(0, t, step)\n",
    "    \n",
    "    # Pick slices at the computed indices\n",
    "    picked_slices = arr[indices]\n",
    "    \n",
    "    return picked_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The one function to run for pseudo calibration, which will include all the previous steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseud_calibration(arr, block_size, reg= 50, stride = 4):\n",
    "    slices = slice_array(arr, block_size,stride)\n",
    "    t, x, y = arr.shape\n",
    "    medslice = [sorted_uniform_pictures(s[0]) for s in slices]\n",
    "    tenth = [pick_regular_slices(s, reg) for s in medslice]\n",
    "    meaned = [np.mean(t, axis=0) for t in tenth]\n",
    "    reconstructed = rebuild_array(list(zip(meaned, [(s[1][0], s[1][1], s[1][2], s[1][3]) for s in slices])), (t, x, y), block_size)\n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. loop and record data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_dict_of_dicts_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_metrics ={\n",
    "                \"method_1\": {},\n",
    "                \"method_2\": {},\n",
    "                \"method_3\": {},\n",
    "                \"raw\"     : {}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop around for method 1, 2, 3:  \n",
    "- return calibrated sequence as an array\n",
    "- normalizes the array\n",
    "- store it into the corresponding level two part of the dictionary  \n",
    "\n",
    "Note that each method takes increasingly more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialisation for the loops of the calibration and scene images\n",
    "cal_scene1_images = np.stack(scene_df1[\"image\"].values)\n",
    "calibrated_scene = calibration_matching(scene_df1, calibration_df1)\n",
    "\n",
    "all_scene_df = [scene_df1,scene_df2,scene_df3,car_scene_df1,car_scene_df2,car_scene_df3]\n",
    "all_scenes_keys = [\"scene_1\",\"scene_2\",\"scene_3\",\"car_scene_1\",\"car_scene_2\",\"car_scene_3\"]\n",
    "all_calib =[calibration_df2,car_calibration_df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , scene_df in enumerate(all_scene_df):\n",
    "    calibration_df = all_calib[0] if i <3 else all_calib[1]\n",
    "    calibrated = calibration_matching(scene_df, calibration_df)\n",
    "    data_for_metrics[\"method_1\"].update({all_scenes_keys[i] : normalize(calibrated)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , scene_df in enumerate(all_scene_df):\n",
    "    calibration_df = all_calib[0] if i <3 else all_calib[1]\n",
    "    calibrated = applier(calibration_df,scene_df)\n",
    "    data_for_metrics[\"method_2\"].update({all_scenes_keys[i] : normalize(calibrated)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , scene_df in enumerate(all_scene_df):\n",
    "    arr = np.stack(scene_df[\"image\"].values)\n",
    "    calibrated = pseud_calibration(arr,32,int(len(arr)/5),4)\n",
    "    data_for_metrics[\"method_3\"].update({all_scenes_keys[i] :normalize(calibrated)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For storing raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , scene_df in enumerate(all_scene_df):\n",
    "    arr = np.stack(scene_df[\"image\"].values)\n",
    "    data_for_metrics[\"raw\"].update({all_scenes_keys[i] :normalize(arr)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally -- this takes a minute or two AND the resulting file is around 14,7 GB.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_of_dicts_pickle(data_for_metrics,\"data_for_metrics.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
