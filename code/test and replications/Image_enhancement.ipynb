{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fondation \n",
    "\n",
    "Essential to run all this section: load the pickl of our experiment (think to change the path ;)  \n",
    "You can print level on and level two keys in case you have a doubt  (cell 5) one can use these list to loop over the dataset  \n",
    "- Level 1 will let you chose which method you want to see: raw, or method 1,2, or 3  (corresponding to each challenge)\n",
    "- level 2 which of the 6 sequence  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_of_dicts_pickle(filename):\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dict_of_dicts_pickle(r\"C:\\Users\\WillQuantique\\OneDrive - univ-lyon2.fr\\Fac\\M1\\DataChallege\\git\\M1_S8_dataChallenge_24\\code\\test_jupyter_notebook\\data_for_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_one_keys = list(data.keys())\n",
    "level_two_keys =[]\n",
    "for k in level_one_keys:\n",
    "    level_two_keys.extend(list(data[k].keys()))\n",
    "level_two_keys = set(level_two_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['method_1', 'method_2', 'method_3', 'raw']\n",
      "{'car_scene_2', 'scene_1', 'car_scene_3', 'scene_3', 'car_scene_1', 'scene_2'}\n"
     ]
    }
   ],
   "source": [
    "print(level_one_keys)\n",
    "print(level_two_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building blocks\n",
    "Here you will find the bulding blocks for the autoadjustment functions  \n",
    "Don't hesitate to build your own (you may add new metrics function here to help fo r that matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_uniform_pictures(arr):\n",
    "    \"\"\"\n",
    "    Sort (t, x, y) array's t slices from most uniform to least uniform.\n",
    "\n",
    "    Parameters:\n",
    "    arr (np.ndarray): Input 3D array of shape (t, x, y).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A 3D array where the t slices are sorted by uniformity.\n",
    "    \"\"\"\n",
    "    t, x, y = arr.shape\n",
    "    \n",
    "    # Compute the variance for each t slice\n",
    "    variances = np.var(arr, axis=(1, 2))\n",
    "    \n",
    "    # Get the sorted indices based on variances\n",
    "    sorted_indices = np.argsort(variances)\n",
    "    \n",
    "    # Extract and sort the t slices\n",
    "    sorted_slices = arr[sorted_indices]\n",
    "    \n",
    "    return sorted_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_video_from_images(images, output_filename, fps=60):\n",
    "    \"\"\"\n",
    "    Save a sequence of images as a video.\n",
    "\n",
    "    Parameters:\n",
    "    images (list or array): List or array of images (each image should be a 2D or 3D NumPy array).\n",
    "    output_filename (str): Output video filename (e.g., 'output.avi').\n",
    "    fps (int): Frames per second for the video.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the images\n",
    "    height, width = images[0].shape[:2]\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))\n",
    "\n",
    "    for img in images:\n",
    "        # Ensure image is in the correct format (uint8)\n",
    "        img_uint8 = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        # If the image is grayscale, convert it to BGR\n",
    "        if len(img_uint8.shape) == 2:\n",
    "            img_uint8 = cv2.cvtColor(img_uint8, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(img_uint8)\n",
    "\n",
    "    # Release everything when the job is finished\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_luminosity_contrast(image: np.ndarray, alpha: float, beta: int) -> np.ndarray:\n",
    "    adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return adjusted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_features(image: np.ndarray) -> int:\n",
    "    orb = cv2.ORB_create()\n",
    "    if image is None or image.size == 0 or len(image.shape) != 2:\n",
    "        return 0\n",
    "    keypoints = orb.detect(image, None)\n",
    "    return len(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_with_least_features(array):\n",
    "    orb = cv2.ORB_create()\n",
    "    feature_counts = []\n",
    "    \n",
    "    for t in range(array.shape[0]):\n",
    "        slice_t = array[t]\n",
    "        slice_t = slice_t.astype(np.uint8)\n",
    "        keypoints = orb.detect(slice_t, None)\n",
    "        feature_counts.append(len(keypoints))\n",
    "    \n",
    "    min_features_idx = np.argmin(feature_counts)\n",
    "    return array[min_features_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_check_threshold(array, target_value: float, x: float):\n",
    "    total_values = array.size\n",
    "    target_value_count = np.count_nonzero(array >= target_value)\n",
    "    percentage = (target_value_count / total_values) * 100\n",
    "    return percentage < x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoadjust 1\n",
    "use feature detection as a metric for autoadjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_adjust_luminosity_contrast(image: np.ndarray) -> np.ndarray:\n",
    "    best_feature_count = -1\n",
    "    best_image = None\n",
    "    best_alpha = 0.01\n",
    "    best_beta = 0\n",
    "    if len(image.shape)==3:\n",
    "        image = sorted_uniform_pictures(image)[int(len(image)/2)]\n",
    "    print(image.shape)\n",
    "    alpha_range = np.arange(0.0, 1.5, 0.005)\n",
    "    beta_range = np.arange(0, 100, 5)\n",
    "\n",
    "    \n",
    "    for beta in beta_range:\n",
    "        for alpha in alpha_range:\n",
    "            adjusted_image = adjust_luminosity_contrast(image, alpha, beta)\n",
    "            if adjusted_image is None or adjusted_image.size == 0 or np.isnan(adjusted_image).any():\n",
    "                continue\n",
    "            current_feature_count = count_features(adjusted_image)\n",
    "\n",
    "            if current_feature_count > best_feature_count:\n",
    "                if count_and_check_threshold(adjusted_image, 255, 99):\n",
    "                    best_feature_count = current_feature_count\n",
    "                    best_image = adjusted_image\n",
    "                    best_alpha = alpha\n",
    "                    best_beta = beta\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    if best_image is None:\n",
    "        raise ValueError(\"No valid image was found. Please check the input image and parameters.\")\n",
    "    \n",
    "    print(f\"Best alpha: {best_alpha}, Best beta: {best_beta}\")\n",
    "    return best_image, best_alpha, best_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto adjust 2\n",
    "Uses standard deviation as a metric to find a sweet spot for adjusting the contrast  \n",
    "Then uses the mean as a metric to adjust for luminosity.  \n",
    "The margine of error account for 256 possible pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_adjust_luminosity_contrast_2(image: np.ndarray) -> np.ndarray:\n",
    "    best_image = None\n",
    "    best_alpha = 0.01\n",
    "    best_beta = 0\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        image = image[int(len(image) / 2)]\n",
    "    \n",
    "    alpha_range = np.arange(0.0, 2.0, 0.005)\n",
    "    beta_range = np.arange(-100, 300, 5)\n",
    "\n",
    "    # Find best alpha based on standard deviation\n",
    "    best_metric = -1\n",
    "    for alpha in alpha_range:\n",
    "        adjusted_image = adjust_luminosity_contrast(image, alpha, 0)\n",
    "        if adjusted_image is None or adjusted_image.size == 0 or np.isnan(adjusted_image).any():\n",
    "            continue\n",
    "        \n",
    "        current_std = np.std(adjusted_image)\n",
    "        \n",
    "        if current_std > best_metric and 10 < current_std < 100:\n",
    "            best_metric = current_std\n",
    "            best_alpha = alpha\n",
    "            best_image = adjusted_image\n",
    "    \n",
    "    if best_image is None:\n",
    "        raise ValueError(\"No valid image was found in the first pass. Please check the input image and parameters.\")\n",
    "    \n",
    "    # Now, find the best beta based on mean brightness\n",
    "    best_metric = -1\n",
    "    final_best_image = None\n",
    "    for beta in beta_range:\n",
    "        adjusted_image = adjust_luminosity_contrast(image, best_alpha, beta)\n",
    "        if adjusted_image is None or adjusted_image.size == 0 or np.isnan(adjusted_image).any():\n",
    "            continue\n",
    "        \n",
    "        current_mean_brightness = np.mean(adjusted_image)\n",
    "        \n",
    "        if current_mean_brightness > best_metric and 50 < current_mean_brightness < 200:\n",
    "            best_metric = current_mean_brightness\n",
    "            best_beta = beta\n",
    "            final_best_image = adjusted_image\n",
    "    \n",
    "    if final_best_image is None:\n",
    "        raise ValueError(\"No valid image was found in the second pass. Please check the input image and parameters.\")\n",
    "    \n",
    "    return final_best_image, best_alpha/10, best_beta/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the part where you can make a mess and explore the data at wil ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
