{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %%capture --no-stderr\n",
    "# %%capture output\n",
    "# https://ipython.readthedocs.io/en/stable/interactive/magics.html#cellmagic-capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/TIMOLEEGO/LSC-CNN\n",
    "\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9432740"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "https://stackoverflow.com/questions/71182396/modulenotfounderror-no-module-named-skimage-measure-simple-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
    "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
    "        nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_PSNR(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    PSNR = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (PSNR/Img.shape[0])\n",
    "\n",
    "def batch_SSIM(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    SSIM = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        SSIM += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (SSIM/Img.shape[0])\n",
    "\n",
    "def batch_MSE(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    MSE = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        MSE += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (MSE/Img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(image, mode):\n",
    "    out = np.transpose(image, (1,2,0))\n",
    "    #out = image\n",
    "    if mode == 0:\n",
    "        # original\n",
    "        out = out\n",
    "    elif mode == 1:\n",
    "        # flip up and down\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 2:\n",
    "        # rotate counterwise 90 degree\n",
    "        out = np.rot90(out)\n",
    "    elif mode == 3:\n",
    "        # rotate 90 degree and flip up and down\n",
    "        out = np.rot90(out)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 4:\n",
    "        # rotate 180 degree\n",
    "        out = np.rot90(out, k=2)\n",
    "    elif mode == 5:\n",
    "        # rotate 180 degree and flip\n",
    "        out = np.rot90(out, k=2)\n",
    "        out = np.flipud(out)\n",
    "    elif mode == 6:\n",
    "        # rotate 270 degree\n",
    "        out = np.rot90(out, k=3)\n",
    "    elif mode == 7:\n",
    "        # rotate 270 degree and flip\n",
    "        out = np.rot90(out, k=3)\n",
    "        out = np.flipud(out)\n",
    "    return np.transpose(out, (2,0,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "import torch.utils.data as udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return data/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Im2Patch(img, win, stride=1):\n",
    "    k = 0\n",
    "    endc = img.shape[0]\n",
    "    endw = img.shape[1]\n",
    "    endh = img.shape[2]\n",
    "    patch = img[:, 0:endw-win+0+1:stride, 0:endh-win+0+1:stride]\n",
    "    TotalPatNum = patch.shape[1] * patch.shape[2]\n",
    "    Y = np.zeros([endc, win*win,TotalPatNum], np.float32)\n",
    "    for i in range(win):\n",
    "        for j in range(win):\n",
    "            patch = img[:,i:endw-win+i+1:stride,j:endh-win+j+1:stride]\n",
    "            Y[:,k,:] = np.array(patch[:]).reshape(endc, TotalPatNum)\n",
    "            k = k + 1\n",
    "    return Y.reshape([endc, win, win, TotalPatNum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path, patch_size, stride, aug_times=1):\n",
    "    # train\n",
    "    print('process training data')\n",
    "    scales = [1, 0.9, 0.8, 0.7]\n",
    "    #files = glob.glob(os.path.join(data_path, 'grayimages', '*'))\n",
    "\n",
    "    files = glob.glob(os.path.join(data_path, 'train','*'))\n",
    "    files.sort()\n",
    "    # h5f = h5py.File('train.h5', 'w')\n",
    "    h5f = h5py.File('train.h5', 'r')\n",
    "    train_num = 0\n",
    "    for i in range(len(files)):\n",
    "        img = cv2.imread(files[i])\n",
    "        h, w, c = img.shape\n",
    "        for k in range(len(scales)):\n",
    "            Img = cv2.resize(img, (int(h*scales[k]), int(w*scales[k])), interpolation=cv2.INTER_CUBIC)\n",
    "            Img = np.expand_dims(Img[:,:,0].copy(), 0)\n",
    "            Img = np.float32(normalize(Img))\n",
    "            patches = Im2Patch(Img, win=patch_size, stride=stride)\n",
    "            print(\"file: %s scale %.1f # samples: %d\" % (files[i], scales[k], patches.shape[3]*aug_times))\n",
    "            for n in range(patches.shape[3]):\n",
    "                data = patches[:,:,:,n].copy()\n",
    "                h5f.create_dataset(str(train_num), data=data)\n",
    "                train_num += 1\n",
    "                for m in range(aug_times-1):\n",
    "                    data_aug = data_augmentation(data, np.random.randint(1,8))\n",
    "                    h5f.create_dataset(str(train_num)+\"_aug_%d\" % (m+1), data=data_aug)\n",
    "                    train_num += 1\n",
    "    h5f.close()\n",
    "    # val\n",
    "    print('\\nprocess validation data')\n",
    "    #files.clear()\n",
    "\n",
    "    files = glob.glob(os.path.join(data_path,'val','*'))\n",
    "    files.sort()\n",
    "    # h5f = h5py.File('val.h5', 'w')\n",
    "    h5f = h5py.File('val.h5', 'r')\n",
    "    val_num = 0\n",
    "    for i in range(len(files)):\n",
    "        print(\"file: %s\" % files[i])\n",
    "        img = cv2.imread(files[i])\n",
    "        img = np.expand_dims(img[:,:,0], 0)\n",
    "        img = np.float32(normalize(img))\n",
    "        h5f.create_dataset(str(val_num), data=img)\n",
    "        val_num += 1\n",
    "    h5f.close()\n",
    "    print('training set, # samples %d\\n' % train_num)\n",
    "    print('val set, # samples %d\\n' % val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(udata.Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            h5f = h5py.File('train.h5', 'r')\n",
    "        else:\n",
    "            h5f = h5py.File('val.h5', 'r')\n",
    "        self.keys = list(h5f.keys())\n",
    "        random.shuffle(self.keys)\n",
    "        h5f.close()\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            h5f = h5py.File('train.h5', 'r')\n",
    "        else:\n",
    "            h5f = h5py.File('val.h5', 'r')\n",
    "        key = self.keys[index]\n",
    "        data = np.array(h5f[key])\n",
    "        h5f.close()\n",
    "        return torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import \\\n",
    "    Conv2D,Input,add,Activation,BatchNormalization,Multiply,Subtract,Concatenate,Conv2DTranspose\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import six\n",
    "\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_layer(x):\n",
    "    return tf.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADresnetBuilder(object):\n",
    "    def build(self, block_fn, repetitions):\n",
    "        input_shape = (None,None,1)\n",
    "        self._handle_dim_ordering()\n",
    "        block_fn = self._get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = self._conv_bn_relu(filters=128, kernel_size=(7, 7), strides=(1, 1), padding='same')(input)#0708\n",
    "        conv2 = self._conv_bn_relu(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv1)\n",
    "        conv3 = self._conv_bn_relu(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same')(conv2)  #0708\n",
    "\n",
    "        block = conv3\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = self._residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "        block = self._bn_relu(block)\n",
    "        block = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same')(block)\n",
    "        block = self._bn_relu(block)\n",
    "        block = Conv2D(filters=1,kernel_size=3,padding='same')(block)\n",
    "        out = Concatenate(3)([input,block])\n",
    "        out = Activation('relu')(out)\n",
    "        out = Conv2D(filters=1,kernel_size=3,padding='same')(out)\n",
    "        out = Multiply()([out,block])\n",
    "        out2 = Subtract()([input,out])\n",
    "        model = Model(inputs=input, outputs=out2)\n",
    "        return model\n",
    "\n",
    "\n",
    "    # @staticmethod\n",
    "    def build_resnet18(self):\n",
    "        return self.build(self.basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    # @staticmethod\n",
    "    def build_resnet34(self):\n",
    "        return self.build( self.basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    # @staticmethod\n",
    "    def build_resnet50(self):\n",
    "        return self.build( self.bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    # @staticmethod\n",
    "    def build_resnet101(self):\n",
    "        return self.build(self.bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    # @staticmethod\n",
    "    def build_resnet152(self):\n",
    "        return self.build(self.bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "    def _bn_relu(self,input):\n",
    "        \"\"\"Helper to build a BN -> relu block\n",
    "        \"\"\"\n",
    "        norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "        return Activation(\"relu\")(norm)\n",
    "\n",
    "    def _conv_bn_relu(self,**conv_params):\n",
    "        \"\"\"Helper to build a conv -> BN -> relu block\n",
    "        \"\"\"\n",
    "        filters = conv_params[\"filters\"]\n",
    "        kernel_size = conv_params[\"kernel_size\"]\n",
    "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "        def f(input):\n",
    "            conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                          strides=strides, padding=padding,\n",
    "                          kernel_regularizer=kernel_regularizer)(input)\n",
    "            return self._bn_relu(conv)\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    def _bn_relu_conv(self,**conv_params):\n",
    "        \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "        This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "        \"\"\"\n",
    "        filters = conv_params[\"filters\"]\n",
    "        kernel_size = conv_params[\"kernel_size\"]\n",
    "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "        def f(input):\n",
    "            activation = self._bn_relu(input)\n",
    "            return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                          strides=strides, padding=padding,\n",
    "                          kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    def _shortcut(self,input, residual):\n",
    "        \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "        \"\"\"\n",
    "        # Expand channles of shortcut to match residual.\n",
    "        # Stride appropriately to match residual (width, height)\n",
    "        # Should be int if network architecture is correctly configured.\n",
    "        input_shape = K.int_shape(input)\n",
    "        residual_shape = K.int_shape(residual)\n",
    "        stride_width = 1\n",
    "        stride_height = 1\n",
    "        equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "        shortcut = input\n",
    "        # 1 X 1 conv if shape is different. Else identity.\n",
    "        if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "            shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                              kernel_size=(1, 1),\n",
    "                              strides=(stride_width, stride_height),\n",
    "                              padding=\"valid\",\n",
    "                              kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "        return add([shortcut, residual])\n",
    "\n",
    "\n",
    "    def _residual_block(self,block_function, filters, repetitions, is_first_layer=False):\n",
    "        \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "        \"\"\"\n",
    "        def f(input):\n",
    "            for i in range(repetitions):\n",
    "                init_strides = (1, 1)\n",
    "                if i == 0 and not is_first_layer:\n",
    "                    init_strides = (1, 1)\n",
    "                input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                       is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "            return input\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    def basic_block(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "        \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "        \"\"\"\n",
    "        def f(input):\n",
    "\n",
    "            if is_first_block_of_first_layer:\n",
    "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "                conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                               strides=init_strides,\n",
    "                               padding=\"same\",\n",
    "                               #kernel_initializer=\"he_normal\",\n",
    "                               kernel_regularizer=l2(1.e-4))(input)  #1e-6\n",
    "                               #use_bias=False)(input)   #+use_bias=False\n",
    "            else:\n",
    "                conv1 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                      strides=init_strides)(input)\n",
    "                                           #use_bias=False)(input)   #+use_bias=False\n",
    "\n",
    "            residual = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "            return self._shortcut(input, residual)\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    def bottleneck(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "        \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "        Returns:\n",
    "            A final conv layer of filters * 4\n",
    "        \"\"\"\n",
    "        def f(input):\n",
    "\n",
    "            if is_first_block_of_first_layer:\n",
    "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "                conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                                  strides=init_strides,\n",
    "                                  padding=\"same\",\n",
    "                                  #kernel_initializer=\"he_normal\",\n",
    "                                  kernel_regularizer=l2(1.e-4))(input)#1e-4-->6-->4\n",
    "                                  #use_bias=False)(input)    #+use_bias=False\n",
    "            else:\n",
    "                conv_1_1 = self._bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                         strides=init_strides)(input)\n",
    "\n",
    "            conv_3_3 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "            residual = self._bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "            return self._shortcut(input, residual)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def _handle_dim_ordering(self):\n",
    "        global ROW_AXIS\n",
    "        global COL_AXIS\n",
    "        global CHANNEL_AXIS\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = -1#3\n",
    "\n",
    "    def _get_block(self,identifier):\n",
    "        if isinstance(identifier, six.string_types):\n",
    "            res = globals().get(identifier)\n",
    "            if not res:\n",
    "                raise ValueError('Invalid {}'.format(identifier))\n",
    "            return res\n",
    "        return identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras import callbacks\n",
    "import random\n",
    "import tensorflow.keras.optimizers as opt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "   initial_lrate = 0.001\n",
    "   drop = 0.1#0.5\n",
    "   epochs_drop = 40 #5.0\n",
    "   lr = initial_lrate * (drop ** np.floor((1 + epoch) / epochs_drop))\n",
    "   return lr\n",
    "\n",
    "lr = LearningRateScheduler(step_decay) \n",
    "\n",
    "def custom_loss(y_true,y_pred):\n",
    "    diff=y_true-y_pred\n",
    "    res=K.sum(diff*diff)/(2*128)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_path,batch_size):\n",
    "    h5f = h5py.File(data_path, 'r')\n",
    "    keys = list(h5f.keys())\n",
    "    flag=0\n",
    "    batch_img = []\n",
    "    batch_noiseimg = []\n",
    "    random.shuffle(keys)\n",
    "    for k in keys:\n",
    "        img = np.array(h5f[k]).transpose((1,2,0))\n",
    "        G_col = np.random.normal(0, 15 / 255., (1,50))\n",
    "        noise = np.expand_dims(np.tile(G_col, (50, 1)),axis=2)\n",
    "        noise_img = img+noise\n",
    "        batch_img.append(img)\n",
    "        batch_noiseimg.append(noise_img)\n",
    "        flag+=1\n",
    "        if flag==batch_size:\n",
    "            yield (np.array(batch_noiseimg) ,np.array(batch_img))\n",
    "            flag=0\n",
    "            batch_img.clear()\n",
    "            batch_noiseimg.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "log_dir = '../log/'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "check_point = callbacks.ModelCheckpoint('../model.h5',\n",
    "                                     monitor='loss',verbose=1,save_best_only=True, save_weights_only=False, mode='min')\n",
    "vis = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True, write_images=True,\n",
    "                            embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None,\n",
    "                            embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "builder = ADresnetBuilder()\n",
    "model = builder.build_resnet18()\n",
    "model.compile(optimizer=opt.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=1.e-8), loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_dir = 'C:/Users/thang/OneDrive/Desktop/m1_dataChal/LSC-CNN dataset/val.h5'\n",
    "h5f = h5py.File(train_dir, 'r')\n",
    "keys = list(h5f.keys())\n",
    "steps = int(np.floor(len(keys) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "summary_write = tf.summary.create_file_writer(log_dir)\n",
    "for epoch in range(epochs):\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', verbose=1)\n",
    "    train_data=data_generator('../train.h5',batch_size=128)\n",
    "    model.fit(train_data,steps_per_epoch=steps,use_multiprocessing=False,shuffle=True,callbacks=[check_point,vis,reduce_lr,lr])\n",
    "    cap = cv2.VideoCapture('../dym4.avi')\n",
    "    ret = 1\n",
    "    total_psnr = 0  # 0710+\n",
    "    total_mse = 0  # 0710+\n",
    "    total_ssim = 0\n",
    "    starttime = time.clock()\n",
    "    while (ret):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            G_col = np.random.normal(0, 15 / 255., (1, 320))\n",
    "            noise = np.expand_dims(np.tile(G_col, (240, 1)), axis=2)\n",
    "            img = np.expand_dims(frame, axis=2).astype(np.float) / 255.\n",
    "            noise_img = np.expand_dims((img + noise), axis=0)\n",
    "            #cv2.imshow('1', (img + noise))\n",
    "            \n",
    "            # -------------------------------PSNR-MSE-----------------------------------\n",
    "            result = model.predict(noise_img)\n",
    "            raw_img_data = np.array(img, dtype=np.float32)  # dtype=np.float64)\n",
    "            denoise_img_data = np.array(result, dtype=np.float32)  # dtype=np.float64)\n",
    "            mse = (np.abs(raw_img_data - denoise_img_data) ** 2.).mean()\n",
    "            psnr_denoise_raw = 20 * np.log10(1. / np.sqrt(mse))\n",
    "            \n",
    "            # -------------------------------SSIM-------------------------------------\n",
    "            im1 = tf.image.convert_image_dtype(raw_img_data, tf.float32)\n",
    "            im2 = tf.image.convert_image_dtype(denoise_img_data, tf.float32)\n",
    "\n",
    "            ssim_tf = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "            ssim_np = ssim_tf.numpy()\n",
    "            ssim = ssim_np[0]\n",
    "            print(\"PSNR: \", psnr_denoise_raw, \"    SSIM: \", ssim)\n",
    "            with summary_write.as_default():\n",
    "                tf.summary.scalar('PSNR step=epoch', psnr_denoise_raw, step=epoch)\n",
    "                tf.summary.scalar('SSIM step=epoch', ssim, step=epoch)\n",
    "\n",
    "            total_mse += mse\n",
    "            total_psnr += psnr_denoise_raw\n",
    "            total_ssim += ssim\n",
    "            \n",
    "    endtime = time.clock()\n",
    "    totaltime = endtime - starttime\n",
    "    AVG_TIME = totaltime / 269\n",
    "    AVG_PSNR = total_psnr / 269\n",
    "    AVG_MSE = total_mse / 269\n",
    "    AVG_SSIM = total_ssim / 269\n",
    "    \n",
    "    print(\"AVG_PSNR: \", AVG_PSNR)\n",
    "    print(\"AVG_MSE: \", AVG_MSE)\n",
    "    print(\"AVG_TIME: \", AVG_TIME)\n",
    "    print(\"AVG_SSIM: \", AVG_SSIM)\n",
    "\n",
    "    with summary_write.as_default():\n",
    "        tf.summary.scalar('AVG_PSNR step=epoch', AVG_PSNR, step=epoch)\n",
    "        tf.summary.scalar('AVG_MSE step=epoch', AVG_MSE, step=epoch)\n",
    "        tf.summary.scalar('AVG_SSIM step=epoch', AVG_SSIM, step=epoch)\n",
    "        tf.summary.scalar('AVG_TIME step=epoch', AVG_TIME, step=epoch)\n",
    "    if AVG_PSNR>=37:\n",
    "       model.save('../model_37.h5')\n",
    "    if AVG_PSNR>=37.2:\n",
    "       model.save('../model_37_2.h5')\n",
    "    if AVG_PSNR>=37.4:\n",
    "       model.save('../model_37_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"val.h5\" (mode r)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = ADresnetBuilder()\n",
    "model = builder.build_resnet18()\n",
    "input_shape = (None, None, 1)\n",
    "model.build(input_shape)\n",
    "model.load_weights('model_37_4.h5')\n",
    "cap = cv2.VideoCapture('real.avi')  #change test file\n",
    "i = 0\n",
    "ret = 1\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "total_time = 0\n",
    "while (ret):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        G_col = np.random.normal(0, 15 / 255., (1, 320))\n",
    "        noise = np.expand_dims(np.tile(G_col, (240, 1)), axis=2)\n",
    "        img = np.expand_dims(frame,axis=2).astype(np.float)/255.\n",
    "        noise_img = np.expand_dims((img + noise),axis=0)\n",
    "        #cv2.imshow('1',(img + noise))\n",
    "        cv2.imwrite('./test/noise' + '/' + '%d.png' % i, (img + noise))\n",
    "        starttime = time.clock()\n",
    "        result = model.predict(noise_img)\n",
    "        single_time = time.clock() - starttime\n",
    "        print(single_time)\n",
    "        #-------------------------------PSNR------------------------------------\n",
    "        raw_img_data = np.array(img,dtype=np.float64)\n",
    "        denoise_img_data = np.array(result,dtype=np.float64)\n",
    "        #----------------------------MSE----------------------------------------\n",
    "        mse = (np.abs(raw_img_data-denoise_img_data)**2.).mean()\n",
    "        psnr_denoise_raw = 20*np.log10(1./np.sqrt(mse))\n",
    "        print(psnr_denoise_raw)\n",
    "        # -------------------------SSIM------------------------------------------\n",
    "        im1 = tf.image.convert_image_dtype(raw_img_data, tf.float32)\n",
    "        im2 = tf.image.convert_image_dtype(denoise_img_data, tf.float32)\n",
    "        ssim_tf = tf.image.ssim(im1, im2, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "        ssim_np = ssim_tf.numpy()\n",
    "        ssim = ssim_np[0]\n",
    "        print(\"ssim:\",ssim)\n",
    "        total_psnr += psnr_denoise_raw\n",
    "        total_ssim += ssim\n",
    "        #-----------------------------------------------------------------------\n",
    "        result = np.clip(np.squeeze(result)*255,0,255).astype(np.uint8)\n",
    "        total_time += single_time\n",
    "        cv2.imwrite('./test/real' + '/' + '%d.png' % i, result)\n",
    "        i += 1\n",
    "        cv2.waitKey(1)\n",
    "print(\"avg_psnr:\", total_psnr/269) #real.avi->269frame\n",
    "print(\"avg_ssim:\", total_ssim/269)\n",
    "print(\"avg_time:\", total_time/269)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
